{
 "metadata": {
  "name": "",
  "signature": "sha256:b2965844d158c8db61cf21ac7cef713bba8934722a03af6f99a95a431d68eeac"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os.path as p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_title = pd.read_csv(\"/home/rmyeid/notebooks/compsocial/SPSSI_Survey_1_Complete.csv\",  header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df_title.drop(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "357\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data Cleaning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. ~~Create a new column, which labels monoculturals, biculturals and multiculturals~~\n",
      "1. ~~Categorize cultural labels into Census groups (quantify demographics)~~\n",
      "1. Determine subgroups of monoculturals and biculturals (based on ingroup prototypicality)\n",
      "1. ~~Create a sub-dataset for the SPSSI poster~~ \n",
      "1. ~~Check for missing data~~"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[\"identity_categorization\"] = np.nan\n",
      "monocultural_index = (np.logical_not(df.IDEN_1A.isnull())) \n",
      "df.loc[monocultural_index, \"identity_categorization\"]=\"monocultural\"\n",
      "bicultural_index = (np.logical_not(df.IDEN_1A.isnull())) * (np.logical_not(df.IDEN_2A.isnull())) * (df.IDEN_3A.isnull())\n",
      "df.loc[bicultural_index,\"identity_categorization\"]=\"bicultural\"\n",
      "multicultural_index = (np.logical_not(df.IDEN_1A.isnull())) * (np.logical_not(df.IDEN_2A.isnull())) * (np.logical_not(df.IDEN_3A.isnull()))\n",
      "df.loc[multicultural_index, \"identity_categorization\"] = \"multicultural\"\n",
      "df.identity_categorization.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "monocultural     153\n",
        "bicultural       152\n",
        "multicultural     35\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Missing Data Cleaning\n",
      "\n",
      "We need to remove people who did not fill the census and the primary identity data "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.identity_categorization.isnull()][[\"IDEN_1A\", \"CEN_1_1\"]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>IDEN_1A</th>\n",
        "      <th>CEN_1_1</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>160</th>\n",
        "      <td> NaN</td>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>184</th>\n",
        "      <td> NaN</td>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>192</th>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>223</th>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>229</th>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>336</th>\n",
        "      <td> NaN</td>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>337</th>\n",
        "      <td> NaN</td>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>338</th>\n",
        "      <td> NaN</td>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>339</th>\n",
        "      <td> NaN</td>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>340</th>\n",
        "      <td> NaN</td>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>341</th>\n",
        "      <td> NaN</td>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>342</th>\n",
        "      <td> NaN</td>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>343</th>\n",
        "      <td> NaN</td>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>346</th>\n",
        "      <td> NaN</td>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>347</th>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>348</th>\n",
        "      <td> NaN</td>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>354</th>\n",
        "      <td> NaN</td>\n",
        "      <td>   1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 104,
       "text": [
        "    IDEN_1A CEN_1_1\n",
        "160     NaN       1\n",
        "184     NaN       1\n",
        "192     NaN     NaN\n",
        "223     NaN     NaN\n",
        "229     NaN     NaN\n",
        "336     NaN       1\n",
        "337     NaN       1\n",
        "338     NaN       1\n",
        "339     NaN       1\n",
        "340     NaN       1\n",
        "341     NaN       1\n",
        "342     NaN       1\n",
        "343     NaN       1\n",
        "346     NaN       1\n",
        "347     NaN     NaN\n",
        "348     NaN       1\n",
        "354     NaN       1"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df= df.drop(df.index[df.IDEN_1A.isnull() * df.CEN_1_1.isnull()])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Identity Categorization (according to census)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ID_cat_columns =[\"IDEN_1A\", \"IDEN_2A\", \"IDEN_3A\", \"IDEN_4A\", \"CEN_7\", \"GEN_M_1A\", \n",
      "                 \"GEN_M_2A\", \"GEN_M_3A\", \"GEN_M_4A\"]\n",
      "identities = df[ID_cat_columns].values.flatten()\n",
      "normalized_idenitites = [x.lower().replace(\"and\", \"\").split(\",\") for x in identities if isinstance(x, str)]\n",
      "unique_idens = set([iden.strip() for person in normalized_idenitites for iden in person])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "idens_df = pd.DataFrame.from_records([[x] for  x in list(unique_idens)])\n",
      "idens_df.to_csv(\"identities_map.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 145
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Mapping"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from StringIO import StringIO  # got moved to io in python3.\n",
      "import requests"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = requests.get(\"https://docs.google.com/spreadsheets/d/1vHCDGgb8CjnBb4pA5e-htHOlhdsA55JToZWs3USvEJk/\"\n",
      "                 \"export?format=csv&id=1vHCDGgb8CjnBb4pA5e-htHOlhdsA55JToZWs3USvEJk&gid=665505531\")\n",
      "courses_data = r.content\n",
      "courses_df = pd.read_csv(StringIO(courses_data), index_col=0)\n",
      "courses_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>original</th>\n",
        "      <th>2010 Census categorization</th>\n",
        "      <th>New Census Categorization</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> irish/italian/ british</td>\n",
        "      <td>              white</td>\n",
        "      <td>              white</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>          indian(hindu)</td>\n",
        "      <td>              asian</td>\n",
        "      <td>              asian</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>                mexican</td>\n",
        "      <td> hispanic or latino</td>\n",
        "      <td> hispanic or latino</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>                chinese</td>\n",
        "      <td>              asian</td>\n",
        "      <td>              asian</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>       eastern european</td>\n",
        "      <td>              white</td>\n",
        "      <td>              white</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 153,
       "text": [
        "                 original 2010 Census categorization New Census Categorization\n",
        "0  irish/italian/ british                      white                     white\n",
        "1           indian(hindu)                      asian                     asian\n",
        "2                 mexican         hispanic or latino        hispanic or latino\n",
        "3                 chinese                      asian                     asian\n",
        "4        eastern european                      white                     white"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "census10_map = {k:v for k,v in courses_df.values[:, [0,1]]}\n",
      "census12_map = {k:v for k,v in courses_df.values[:, [0,2]]}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "census10 = []\n",
      "census12 = []\n",
      "\n",
      "for person in df[ID_cat_columns].values:\n",
      "  normalized = [x.lower().replace(\"and\", \"\").split(\",\") if isinstance(x, str) else [\"na\"] for x in person]\n",
      "  all_idens = sorted(list(set([x.strip() for col in normalized for x in col])))\n",
      "  idens10 = list(set([census10_map[x] for x in all_idens]))\n",
      "  idens12 = list(set([census12_map[x] for x in all_idens]))\n",
      "\n",
      "  if len(idens10) > 1 and \"n/a\" in idens10: idens10.remove(\"n/a\")\n",
      "  if len(idens12) > 1 and \"n/a\" in idens12: idens12.remove(\"n/a\")\n",
      "\n",
      "  census10.append(\",\".join(sorted(list(set(idens10)))))\n",
      "  census12.append(\",\".join(sorted(list(set(idens12)))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 191
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[\"census10\"] = census10\n",
      "df[\"census12\"] = census12"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[ID_cat_columns + [\"census10\", \"census12\"]].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>IDEN_1A</th>\n",
        "      <th>IDEN_2A</th>\n",
        "      <th>IDEN_3A</th>\n",
        "      <th>IDEN_4A</th>\n",
        "      <th>CEN_7</th>\n",
        "      <th>GEN_M_1A</th>\n",
        "      <th>GEN_M_2A</th>\n",
        "      <th>GEN_M_3A</th>\n",
        "      <th>GEN_M_4A</th>\n",
        "      <th>census10</th>\n",
        "      <th>census12</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>         white</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>         WHITE</td>\n",
        "      <td>         white</td>\n",
        "      <td>         white</td>\n",
        "      <td>         white</td>\n",
        "      <td>                      white</td>\n",
        "      <td>                      white</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>       Chinese</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>       Chinese</td>\n",
        "      <td>       Chinese</td>\n",
        "      <td>       Chinese</td>\n",
        "      <td>       Chinese</td>\n",
        "      <td>                      asian</td>\n",
        "      <td>                      asian</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> Asian Indian </td>\n",
        "      <td>      NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td> Asian Indian </td>\n",
        "      <td> Asian Indian </td>\n",
        "      <td> Asian Indian </td>\n",
        "      <td> Asian Indian </td>\n",
        "      <td>                      asian</td>\n",
        "      <td>                      asian</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Indian(Hindu)</td>\n",
        "      <td> American</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>        Indian</td>\n",
        "      <td> Indian(Hindu)</td>\n",
        "      <td> Indian(Hindu)</td>\n",
        "      <td> Indian(Hindu)</td>\n",
        "      <td>                asian,white</td>\n",
        "      <td>                asian,white</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>      jamaicam</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> Black</td>\n",
        "      <td>           n/a</td>\n",
        "      <td>           n/a</td>\n",
        "      <td>           n/a</td>\n",
        "      <td>           n/a</td>\n",
        "      <td> black or african american </td>\n",
        "      <td> black or african american </td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 195,
       "text": [
        "         IDEN_1A   IDEN_2A IDEN_3A IDEN_4A  CEN_7       GEN_M_1A  \\\n",
        "1          white       NaN     NaN     NaN    NaN          WHITE   \n",
        "2        Chinese       NaN     NaN     NaN    NaN        Chinese   \n",
        "3  Asian Indian        NaN     NaN     NaN    NaN  Asian Indian    \n",
        "4  Indian(Hindu)  American     NaN     NaN    NaN         Indian   \n",
        "5       jamaicam       NaN     NaN     NaN  Black            n/a   \n",
        "\n",
        "        GEN_M_2A       GEN_M_3A       GEN_M_4A                    census10  \\\n",
        "1          white          white          white                       white   \n",
        "2        Chinese        Chinese        Chinese                       asian   \n",
        "3  Asian Indian   Asian Indian   Asian Indian                        asian   \n",
        "4  Indian(Hindu)  Indian(Hindu)  Indian(Hindu)                 asian,white   \n",
        "5            n/a            n/a            n/a  black or african american    \n",
        "\n",
        "                     census12  \n",
        "1                       white  \n",
        "2                       asian  \n",
        "3                       asian  \n",
        "4                 asian,white  \n",
        "5  black or african american   "
       ]
      }
     ],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.to_csv(\"SPSSI_poster_clean.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = df.drop(df.index[df.identity_categorization.isnull()]) #[[\"IDEN_1A\", \"IDEN_2A\", \"IDEN_3A\", \"IDEN_4A\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 228
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Census 2010 stats"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "identity_counts = defaultdict(lambda: 0)\n",
      "census10_counts = df2.census10.value_counts()\n",
      "for x,c  in zip(census10_counts.index.values, census10_counts.values):\n",
      "  for j in [k.strip() for k in x.split(',')]:\n",
      "    identity_counts[j] += c\n",
      "sorted(identity_counts.items(), key=lambda(x,y):y, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 229,
       "text": [
        "[('white', 236),\n",
        " ('asian', 135),\n",
        " ('hispanic or latino', 60),\n",
        " ('black or african american', 32),\n",
        " ('american indian or alaskan native', 5),\n",
        " ('other', 2),\n",
        " ('hipanic/white', 1),\n",
        " ('black or african american/asian', 1),\n",
        " ('native hawaiian or pacific islander', 1)]"
       ]
      }
     ],
     "prompt_number": 229
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Census 2020 stats"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "identity_counts = defaultdict(lambda: 0)\n",
      "census12_counts = df2.census12.value_counts()\n",
      "for x,c  in zip(census12_counts.index.values, census12_counts.values):\n",
      "  for j in [k.strip() for k in x.split(',')]:\n",
      "    identity_counts[j] += c\n",
      "sorted(identity_counts.items(), key=lambda(x,y):y, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 230,
       "text": [
        "[('white', 223),\n",
        " ('asian', 135),\n",
        " ('hispanic or latino', 60),\n",
        " ('black or african american', 32),\n",
        " ('middle eastern', 28),\n",
        " ('american indian or alaskan native', 5),\n",
        " ('other', 2),\n",
        " ('hipanic/white', 1),\n",
        " ('black or african american/asian', 1),\n",
        " ('native hawaiian or pacific islander', 1)]"
       ]
      }
     ],
     "prompt_number": 230
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_mono = df2[df2.identity_categorization==\"monocultural\"]\n",
      "identity_counts = defaultdict(lambda: 0)\n",
      "census10_counts = df_mono.census10.value_counts()\n",
      "for x,c  in zip(census10_counts.index.values, census10_counts.values):\n",
      "  for j in [k.strip() for k in x.split(',')]:\n",
      "    identity_counts[j] += c\n",
      "sorted(identity_counts.items(), key=lambda(x,y):y, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 237,
       "text": [
        "[('asian', 71),\n",
        " ('white', 62),\n",
        " ('hispanic or latino', 30),\n",
        " ('black or african american', 12),\n",
        " ('american indian or alaskan native', 3),\n",
        " ('native hawaiian or pacific islander', 1)]"
       ]
      }
     ],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_bi = df2[df2.identity_categorization==\"bicultural\"]\n",
      "identity_counts = defaultdict(lambda: 0)\n",
      "census10_counts = df_bi.census10.value_counts()\n",
      "for x,c  in zip(census10_counts.index.values, census10_counts.values):\n",
      "  for j in [k.strip() for k in x.split(',')]:\n",
      "    identity_counts[j] += c\n",
      "sorted(identity_counts.items(), key=lambda(x,y):y, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 238,
       "text": [
        "[('white', 140),\n",
        " ('asian', 55),\n",
        " ('hispanic or latino', 27),\n",
        " ('black or african american', 16),\n",
        " ('other', 1),\n",
        " ('american indian or alaskan native', 1),\n",
        " ('black or african american/asian', 1)]"
       ]
      }
     ],
     "prompt_number": 238
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_multi = df2[df2.identity_categorization==\"multicultural\"]\n",
      "identity_counts = defaultdict(lambda: 0)\n",
      "census10_counts = df_multi.census10.value_counts()\n",
      "for x,c  in zip(census10_counts.index.values, census10_counts.values):\n",
      "  for j in [k.strip() for k in x.split(',')]:\n",
      "    identity_counts[j] += c\n",
      "sorted(identity_counts.items(), key=lambda(x,y):y, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 239,
       "text": [
        "[('white', 34),\n",
        " ('asian', 9),\n",
        " ('black or african american', 4),\n",
        " ('hispanic or latino', 3),\n",
        " ('hipanic/white', 1),\n",
        " ('american indian or alaskan native', 1),\n",
        " ('other', 1)]"
       ]
      }
     ],
     "prompt_number": 239
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = df2.loc[df2.identity_categorization==\"monocultural\", [\"IDEN_1A\", \"GEN_M_1A\", \"GEN_M_2A\", \n",
      "                                                      \"GEN_M_3A\", \"GEN_M_4A\", \"census10\"]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 276
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = [42,46,75, 99, 100, 102, 116, 137, 152, 156, 167, 168, 170, 193, 200, 203, 263, 299, 331]\n",
      "[len(x.split(\",\")) for x in df2.loc[rows, \"census10\"]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 274,
       "text": [
        "[2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2]"
       ]
      }
     ],
     "prompt_number": 274
    }
   ],
   "metadata": {}
  }
 ]
}