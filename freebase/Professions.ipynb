{
 "metadata": {
  "name": "",
  "signature": "sha256:4a78c085b0025c5fdae2f162d4c72617ad2188fbe15cdaaeedb6c7388dc0822c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time,sleep\n",
      "from glob import glob\n",
      "import json\n",
      "import urllib\n",
      "import string\n",
      "import cPickle as pickle\n",
      "from os import path\n",
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Querying Freebase"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API_KEY = \"AIzaSyAnupT8pNVHf2WFPidvMcmdrfXgt6RoM0w\"\n",
      "SERVICE_URL = 'https://www.googleapis.com/freebase/v1/mqlread'\n",
      "cursor = \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_iterator(q):\n",
      "  params = {\n",
      "            'query': json.dumps(q),\n",
      "            'key': API_KEY,\n",
      "            'cursor': cursor\n",
      "           }\n",
      "  progress = True\n",
      "  while progress:\n",
      "    url = SERVICE_URL + '?' + urllib.urlencode(params)\n",
      "    try:\n",
      "      response = json.loads(urllib.urlopen(url).read())\n",
      "    except:\n",
      "      sleep(30)\n",
      "      continue\n",
      "    if not 'cursor' in response:\n",
      "      sleep(30)\n",
      "      continue\n",
      "      #raise BadResponse(\"Response does not contain cursor.\")\n",
      "    params['cursor'] = response['cursor']\n",
      "    if response['cursor'] == False:\n",
      "      progress = False\n",
      "    yield response['cursor'], response['result']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Specialization-of attribute"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "null = None\n",
      "query = [{\n",
      "  \"id\": null,\n",
      "  \"name\": null,\n",
      "  \"type\": \"/people/profession\",\n",
      "  \"/people/profession/specialization_of\": []\n",
      "}]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response = []\n",
      "for cursor, partial_results in get_iterator(query):\n",
      "  response.extend(partial_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(response)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "4152"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph = defaultdict(lambda: [])\n",
      "for link in response:\n",
      "  graph[link[\"name\"]].extend(link[\"/people/profession/specialization_of\"])\n",
      "graph = dict(graph)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph[\"Manager\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "[u'Baseball Coach', u'Ironmaster', u'Coach', u'Business executive']"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Specializations attribute"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "null = None\n",
      "query2 = [{\n",
      "  \"id\": null,\n",
      "  \"name\": null,\n",
      "  \"type\": \"/people/profession\",\n",
      "  \"/people/profession/specializations\": []\n",
      "}]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 252
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "specializations = []\n",
      "for cursor, partial_results in get_iterator(query2):\n",
      "  specializations.extend(partial_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-255-cc059087b587>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mspecializations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartial_results\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mspecializations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartial_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-3-b6e262e691f9>\u001b[0m in \u001b[0;36mget_iterator\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m     14\u001b[0m       \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;34m'cursor'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m       \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m       \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m       \u001b[1;31m#raise BadResponse(\"Response does not contain cursor.\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 255
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(specializations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "special_graph = defaultdict(lambda: [])\n",
      "for link in response:\n",
      "  special_graph[link[\"name\"]].extend(link[\"/people/profession/specializations\"])\n",
      "special_graph = dict(special_graph)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'/people/profession/specializations'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-251-0ac2466f2bbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mspecial_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[0mspecial_graph\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"/people/profession/specializations\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mspecial_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: '/people/profession/specializations'"
       ]
      }
     ],
     "prompt_number": 251
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Eliminating double edges"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k in graph:\n",
      "  graph[k] = set(graph[k])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Calculating Depth and All Parents"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parents_cache = graph\n",
      "all_parents_cache = {}\n",
      "depth_cache = {}\n",
      "grandparent_cache = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_parents(k):\n",
      "  if k in parents_cache:\n",
      "    return parents_cache[k]\n",
      "  else:\n",
      "    return []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_depth(k, deep=0):\n",
      "  if deep >= 6:\n",
      "    return 0\n",
      "  if k not in depth_cache:\n",
      "    depths = [get_depth(x, deep+1) for x in get_parents(k)]\n",
      "    depths.append(0)\n",
      "    depth_cache[k] = max(depths) + 1\n",
      "  return depth_cache[k]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_all_parents(k, deep=0):\n",
      "  if deep >= 6: return []\n",
      "  if k not in all_parents_cache:\n",
      "    tmp = list(get_parents(k))\n",
      "    all_parents = list(tmp)\n",
      "    for parent in tmp:\n",
      "      all_parents.extend(get_all_parents(parent, deep+1))\n",
      "    all_parents_cache[k] = list(set(all_parents).difference([k]))\n",
      "  return all_parents_cache[k]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_grandparent(k, deep=0):\n",
      "  if deep >= 6: return k\n",
      "  if not get_parents(k): return k\n",
      "  if k not in grandparent_cache:\n",
      "    grandparents = [get_grandparent(x, deep+1) for x in get_parents(k)]\n",
      "    grandparents = [x for x in grandparents if x]\n",
      "    grandparent_cache[k] = grandparents[0]\n",
      "  return grandparent_cache[k]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k in graph:\n",
      "  get_depth(k)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k in graph:\n",
      "  get_all_parents(k)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k in graph:\n",
      "  grandparent_cache[k] = get_grandparent(k)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 193
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Calculate the Frequency"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle\n",
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "people_db = pickle.load(open(\"/data/csc/fb_persons/100percentpeople.pkl\", \"rb\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freqs = []\n",
      "for x in people_db[[\"profession\"]].dropna().values.flatten():\n",
      "  if isinstance(x, tuple):\n",
      "    freqs.extend(x)\n",
      "  else:\n",
      "    freqs.append(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "people_db = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prof_freq = Counter(freqs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total = float(sum(prof_freq.values()))\n",
      "prof_prob = {k:c/total for k, c in prof_freq.iteritems()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grandparent_cache[\"Lawyer\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 250,
       "text": [
        "u'Criminal defense lawyer'"
       ]
      }
     ],
     "prompt_number": 250
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Strategy #1\n",
      "\n",
      "Merge only the infrequent labels"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_freqs = []\n",
      "threshold = prof_freq.most_common()[200][1]/total\n",
      "for f in freqs:\n",
      "  if prof_prob[f] < threshold:\n",
      "    if (f not in grandparent_cache or\n",
      "    f == grandparent_cache[f] or \n",
      "    grandparent_cache[f] not in prof_prob or \n",
      "    prof_prob[grandparent_cache[f]] < threshold):\n",
      "      new_freqs.append(\"Other\")\n",
      "      continue\n",
      "    else:\n",
      "      new_freqs.append(grandparent_cache[f])\n",
      "\n",
      "  else:\n",
      "    new_freqs.append(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 259
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mapping = defaultdict(lambda: set([]))\n",
      "threshold = prof_freq.most_common()[200][1]/total\n",
      "for f in freqs:\n",
      "  if not f: continue\n",
      "  if prof_prob[f] < threshold:\n",
      "    if (f not in grandparent_cache or\n",
      "    f == grandparent_cache[f] or \n",
      "    grandparent_cache[f] not in prof_prob or \n",
      "    prof_prob[grandparent_cache[f]] < threshold):\n",
      "      mapping[\"Other\"].update([f])\n",
      "      continue\n",
      "    else:\n",
      "      mapping[grandparent_cache[f]].update([f])\n",
      "  else:\n",
      "    mapping[f].update([f])\n",
      "mapping = dict(mapping)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 260
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = Counter(new_freqs)\n",
      "selected_profs = tmp.keys()\n",
      "print len(selected_profs)\n",
      "lines =  u\"\\n\".join([u\"{},{},{}\".format(k,v, \"|\".join(mapping.get(k, []))) for k, v in tmp.most_common()])\n",
      "fh = open(\"professions.csv\", \"w\")\n",
      "fh.write(lines.encode(\"utf8\"))\n",
      "fh.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "203\n"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Startegy #2\n",
      "\n",
      "Merge All"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_freqs2 = []\n",
      "threshold = 2e-5\n",
      "for f in freqs:\n",
      "  if f in grandparent_cache:\n",
      "    g = grandparent_cache[f]\n",
      "    if (g not in prof_prob or \n",
      "       prof_prob[g] < threshold):\n",
      "      new_freqs2.append(\"Other\")\n",
      "    else:\n",
      "      new_freqs2.append(g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = Counter(new_freqs2)\n",
      "selected_profs = tmp.keys()\n",
      "print len(selected_profs)\n",
      "print \"\\n\".join([\"{},{}\".format(k,v) for k, v in tmp.most_common()])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "99\n",
        "Actor,453366\n",
        "Artist,298794\n",
        "Writer,202413\n",
        "Athlete,134553\n",
        "Other,106602\n",
        "Film Producer,98519\n",
        "Film director,76402\n",
        "Politician,51540\n",
        "Editor,49424\n",
        "Television producer,32785\n",
        "Businessperson,28053\n",
        "Scientist,21400\n",
        "Educator,20931\n",
        "Baseball Coach,19645\n",
        "Mathematician,19309\n",
        "Performer,17952\n",
        "Engineer,15234\n",
        "Broadcaster,13957\n",
        "Television Director,13518\n",
        "Referee,10993\n",
        "Entertainer,10526\n",
        "Business executive,10173\n",
        "Set Decorator,7914\n",
        "Entrepreneur,5331\n",
        "Casting Director,5307\n",
        "Historian,4319\n",
        "Soldier,4128\n",
        "Navigator,4094\n",
        "Philosopher,3946\n",
        "Economist,3437\n",
        "Producer,2719\n",
        "Critic,1981\n",
        "Activist,1898\n",
        "Military Officer,1875\n",
        "Peace officer,1700\n",
        "Technician,1473\n",
        "Publisher,908\n",
        "Scholar,872\n",
        "Political Scientist,807\n",
        "Anthropologist,795\n",
        "Accountant,705\n",
        "Television presenter,645\n",
        "Filmmaker,631\n",
        "Salesperson,561\n",
        "Office Worker,380\n",
        "Philanthropist,363\n",
        "Investor,348\n",
        "Social Worker,336\n",
        "Civil servant,321\n",
        "Special effects supervisor,296\n",
        "Stunt Coordinator,287\n",
        "Boom Operator,272\n",
        "Tarento,265\n",
        "Sex worker,261\n",
        "Explorer,259\n",
        "Animation Director,232\n",
        "Warlord,213\n",
        "Foley Artist,198\n",
        "Business magnate,171\n",
        "Set Dresser,151\n",
        "Manufacturer,125\n",
        "Socialite,122\n",
        "Sound Mixer,121\n",
        "Public Servant,116\n",
        "Lighting Director,108\n",
        "Truck driver,108\n",
        "ADR Recordist,106\n",
        "Art collector,100\n",
        "TV Art Director,93\n",
        "ADR Editor,86\n",
        "Sound Department,79\n",
        "Cinematography,76\n",
        "ADR Mixer,75\n",
        "Key Makeup Artist,70\n",
        "Foley Editor,70\n",
        "Bodyguard,70\n",
        "Veteran,70\n",
        "Visual Effects Coordinator,67\n",
        "Foley Mixer,65\n",
        "Advertising Executive,65\n",
        "Nobleman,63\n",
        "Visual Effects,58\n",
        "Script supervisor,55\n",
        "Taxi driver,50\n",
        "Media proprietor,46\n",
        "Mail carrier,46\n",
        "Rector,45\n",
        "ADR Director,45\n",
        "Humanitarian,45\n",
        "Bus driver,44\n",
        "Postal worker,43\n",
        "Special Effects Foreman,43\n",
        "CG Supervisor,43\n",
        "Sound Supervisor,43\n",
        "Bookkeeper,42\n",
        "On-set Dresser,42\n",
        "Foley Recordist,39\n",
        "Ophthalmology,39\n",
        "Special Effects,38\n"
       ]
      }
     ],
     "prompt_number": 248
    }
   ],
   "metadata": {}
  }
 ]
}