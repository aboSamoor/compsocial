{
 "metadata": {
  "name": "",
  "signature": "sha256:f1d6c71faac980f811b955825d836a24c991c3af8a98745ed583b929be0853e5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time,sleep\n",
      "from glob import glob\n",
      "import json\n",
      "import urllib\n",
      "import string\n",
      "import cPickle as pickle\n",
      "from os import path\n",
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "API_KEY = \"AIzaSyAnupT8pNVHf2WFPidvMcmdrfXgt6RoM0w\"\n",
      "SERVICE_URL = 'https://www.googleapis.com/freebase/v1/mqlread'\n",
      "cursor = \"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_iterator(q):\n",
      "  params = {\n",
      "            'query': json.dumps(q),\n",
      "            'key': API_KEY,\n",
      "            'cursor': cursor\n",
      "           }\n",
      "  progress = True\n",
      "  while progress:\n",
      "    url = SERVICE_URL + '?' + urllib.urlencode(params)\n",
      "    try:\n",
      "      response = json.loads(urllib.urlopen(url).read())\n",
      "    except:\n",
      "      sleep(30)\n",
      "      continue\n",
      "    if not 'cursor' in response:\n",
      "      sleep(30)\n",
      "      continue\n",
      "      #raise BadResponse(\"Response does not contain cursor.\")\n",
      "    params['cursor'] = response['cursor']\n",
      "    if response['cursor'] == False:\n",
      "      progress = False\n",
      "    yield response['cursor'], response['result']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "null = None\n",
      "query = [{\n",
      "  \"id\": null,\n",
      "  \"name\": null,\n",
      "  \"type\": \"/people/ethnicity\",\n",
      "  \"/people/ethnicity/included_in_group\": []\n",
      "}]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response = []\n",
      "for cursor, partial_results in get_iterator(query):\n",
      "  response.extend(partial_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph = defaultdict(lambda: [])\n",
      "for link in response:\n",
      "  graph[link[\"name\"]].extend(link[\"/people/ethnicity/included_in_group\"])\n",
      "graph = dict(graph)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(graph)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5686\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parents_cache = graph\n",
      "all_parents_cache = {}\n",
      "depth_cache = {}\n",
      "grandparent_cache = {}\n",
      "\n",
      "def get_parents(k):\n",
      "  if k in parents_cache:\n",
      "    return parents_cache[k]\n",
      "  else:\n",
      "    return []\n",
      "  \n",
      "def get_depth(k, deep=0):\n",
      "  if deep >= 6:\n",
      "    return 0\n",
      "  if k not in depth_cache:\n",
      "    depths = [get_depth(x, deep+1) for x in get_parents(k)]\n",
      "    depths.append(0)\n",
      "    depth_cache[k] = max(depths) + 1\n",
      "  return depth_cache[k]\n",
      "\n",
      "def get_all_parents(k, deep=0):\n",
      "  if deep >= 6: return []\n",
      "  if k not in all_parents_cache:\n",
      "    tmp = list(get_parents(k))\n",
      "    all_parents = list(tmp)\n",
      "    for parent in tmp:\n",
      "      all_parents.extend(get_all_parents(parent, deep+1))\n",
      "    all_parents_cache[k] = list(set(all_parents).difference([k]))\n",
      "  return all_parents_cache[k]\n",
      "\n",
      "def get_grandparent(k, deep=0):\n",
      "  if deep >= 6: return k\n",
      "  if not get_parents(k): return k\n",
      "  if k not in grandparent_cache:\n",
      "    grandparents = [get_grandparent(x, deep+1) for x in get_parents(k)]\n",
      "    grandparents = [x for x in grandparents if x]\n",
      "    grandparent_cache[k] = grandparents[0]\n",
      "  return grandparent_cache[k]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k in graph:\n",
      "  grandparent_cache[k] = get_grandparent(k)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph[\"Arab American\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[u'Asian American']"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Calculate the Frequency"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle\n",
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "people_db = pickle.load(open(\"/data/csc/fb_persons/100percentpeople.pkl\", \"rb\"))\n",
      "freqs = []\n",
      "for x in people_db[[\"ethnicity\"]].dropna().values.flatten():\n",
      "  if isinstance(x, tuple):\n",
      "    freqs.extend(x)\n",
      "  else:\n",
      "    freqs.append(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "people_db = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eth_freq = Counter(freqs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total = float(sum(eth_freq.values()))\n",
      "eth_prob = {k:c/total for k, c in eth_freq.iteritems()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "0.011462612982744454"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Strategy #1\n",
      "\n",
      "Merge only the infrequent labels"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_freqs = []\n",
      "threshold = eth_freq.most_common()[200][1]/total\n",
      "for f in freqs:\n",
      "  if eth_prob[f] < threshold:\n",
      "    if (f not in grandparent_cache or\n",
      "    f == grandparent_cache[f] or \n",
      "    grandparent_cache[f] not in eth_prob or \n",
      "    eth_prob[grandparent_cache[f]] < threshold):\n",
      "      new_freqs.append(\"Other\")\n",
      "      continue\n",
      "    else:\n",
      "      new_freqs.append(grandparent_cache[f])\n",
      "  else:\n",
      "    new_freqs.append(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mapping = defaultdict(lambda: set([]))\n",
      "threshold = eth_freq.most_common()[200][1]/total\n",
      "for f in freqs:\n",
      "  if not f: continue\n",
      "  if eth_prob[f] < threshold:\n",
      "    if (f not in grandparent_cache or\n",
      "    f == grandparent_cache[f] or \n",
      "    grandparent_cache[f] not in eth_prob or \n",
      "    eth_prob[grandparent_cache[f]] < threshold):\n",
      "      mapping[\"Other\"].update([f])\n",
      "      continue\n",
      "    else:\n",
      "      mapping[grandparent_cache[f]].update([f])\n",
      "  else:\n",
      "    mapping[f].update([f])\n",
      "mapping = dict(mapping)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = Counter(new_freqs)\n",
      "selected_profs = tmp.keys()\n",
      "print len(selected_profs)\n",
      "lines =  u\"\\n\".join([u\"{},{},{}\".format(k,v, \"|\".join(mapping[k])) for k, v in tmp.most_common()])\n",
      "fh = open(\"ethnicities.csv\", \"w\")\n",
      "fh.write(lines.encode(\"utf8\"))\n",
      "fh.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "202\n"
       ]
      }
     ],
     "prompt_number": 62
    }
   ],
   "metadata": {}
  }
 ]
}